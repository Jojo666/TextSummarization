# Text Summarization
The practise of condensing the most significant information from a source text to produce an abridged version for a specific user and task is known as text summarising. Summarization in text, specifically, can be extremely useful as it saves the users having to read long articles , blogs or other pieces of text. 

BART is a denoising autoencoder for pretraining sequence-to-sequence models. As described in their paper, BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. As a result, BART performs well on multiple tasks like abstractive dialogue, question answering and summarization.



